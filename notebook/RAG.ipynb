{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "838e6748",
   "metadata": {},
   "source": [
    "- Fine-tuning:\n",
    "Like training a new employee from scratch until they memorize your company's rules.\n",
    "- RAG:\n",
    "Like giving an employee a handbook and letting them look up answers whenever asked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c918592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9972845b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks sample keys: dict_keys(['complaint_id', 'product', 'chunk_id', 'chunk_text'])\n",
      "Chunks sample content: {'complaint_id': 3729558, 'product': 'Credit card', 'chunk_id': 0, 'chunk_text': 'these past few months have been very difficult for everyone despite the fact that people are doing all they can to pay their monthly bills credit card companies are taking advantage of the situation to add late fees where it should be forbidden i paid mine late a few days late but i paid therefore when i requested there should be helping people when didnt want to remove my late fee even though i paid 10000 in interest this is racket credit card companies should be barred from assessing late fees in these times'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks sample keys: dict_keys(['complaint_id', 'product', 'chunk_id', 'chunk_text'])\n",
      "Chunks sample content: {'complaint_id': 7422836, 'product': 'Personal loan', 'chunk_id': 0, 'chunk_text': 'buy now pay later payment for one expense  affirm did not make reporting of any good standing loans to credit bureaus a part of the initial agreement agreement stated that late payments and defaults may be reported but there are no late payments company reported payment as an open installment loan account on xxxx credit report negatively affecting credit score and credit worthiness company refused to rectify issue ive used affirm 8 times previously with no reporting to credit bureaus agreement and loan reporting practices are intentionally deceptive and harmful'}\n",
      "Chunks sample keys: dict_keys(['complaint_id', 'product', 'chunk_id', 'chunk_text'])\n",
      "Chunks sample content: {'complaint_id': 4339332, 'product': 'Personal loan', 'chunk_id': 0, 'chunk_text': 'i never took out a student loan under my name xxxx xxxx'}\n",
      "Chunks sample keys: dict_keys(['complaint_id', 'product', 'chunk_id', 'chunk_text'])\n",
      "Chunks sample content: {'complaint_id': 10464495, 'product': 'Credit card', 'chunk_id': 0, 'chunk_text': 'prepaid cards do not work online or in store at any retailer whatsoever cards have not been used whatsoever and had purchases denied when attempted to use in person when contacting the company they have told me the cards were blocked or denied and sent new ones where the same thing has happened'}\n",
      "Markdown evaluation report saved to /home/nurye/Desktop/10_Academy/week_6/Intelligent-Complaint-Analysis-for-Financial-Services/outputs/evaluation_report.md\n",
      "Full evaluation with auto scoring:\n",
      "                                            Question  \\\n",
      "0  How do customers feel about credit card late f...   \n",
      "1     Are there complaints about buy now, pay later?   \n",
      "2       Is there dissatisfaction with student loans?   \n",
      "3  What are the most common problems with prepaid...   \n",
      "\n",
      "                                              Answer  \\\n",
      "0                   I don't have enough information.   \n",
      "1                                                Yes   \n",
      "2                   I don't have enough information.   \n",
      "3  cards have not been used whatsoever and had pu...   \n",
      "\n",
      "                                       Top_1_Context  \\\n",
      "0  these past few months have been very difficult...   \n",
      "1  buy now pay later payment for one expense  aff...   \n",
      "2  i never took out a student loan under my name ...   \n",
      "3  prepaid cards do not work online or in store a...   \n",
      "\n",
      "                                       Top_2_Context  Score  \\\n",
      "0  i ve been issued a number of late fee that are...      1   \n",
      "1  there are still late payment remarks and updat...      3   \n",
      "2  took out a student loan for xxxx university in...      1   \n",
      "3  a prepaid card was issue in my name i never ap...      3   \n",
      "\n",
      "                                             Comment  \n",
      "0  No relevant information found in retrieved con...  \n",
      "1  Answer somewhat supported by context, moderate...  \n",
      "2  No relevant information found in retrieved con...  \n",
      "3  Answer somewhat supported by context, moderate...  \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Add src folder to Python path for imports\n",
    "SRC_PATH = os.path.join(PROJECT_ROOT, 'src')\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.append(SRC_PATH)\n",
    "\n",
    "from src.evaluate_rag import evaluate_rag\n",
    "from src.evaluate_and_report import evaluate_and_generate_report_auto\n",
    "\n",
    "INDEX_PATH = os.path.join(PROJECT_ROOT, \"vector_store\", \"faiss_index.idx\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"vector_store\", \"metadata.pkl\")\n",
    "OUTPUT_PATH = os.path.join(PROJECT_ROOT, \"outputs\", \"evaluation_report.md\")\n",
    "\n",
    "sample_questions = [\n",
    "    \"How do customers feel about credit card late fees?\",\n",
    "    \"Are there complaints about buy now, pay later?\",\n",
    "    \"Is there dissatisfaction with student loans?\",\n",
    "    \"What are the most common problems with prepaid cards?\"\n",
    "]\n",
    "\n",
    "# Run full evaluation + auto scoring + report generation\n",
    "df_results = evaluate_and_generate_report_auto(\n",
    "    sample_questions, INDEX_PATH, METADATA_PATH, OUTPUT_PATH, top_k=5\n",
    ")\n",
    "print(\"Full evaluation with auto scoring:\")\n",
    "print(df_results.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cce40d4",
   "metadata": {},
   "source": [
    "| Principle                      | Description                                                                        | Did We Address It?           | How?                                                                                                                                                       |\n",
    "| ------------------------------ | ---------------------------------------------------------------------------------- | ---------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Text Relevance**             | Are the text fields useful for the downstream task (e.g., complaint narratives)?   |  Yes                        | I filtered only complaints with non-empty `narrative` and cleaned them for relevant text only.                                                           |\n",
    "| **Semantic Integrity**         | Does the text still preserve meaning after cleaning/chunking?                      |  Yes (with room to improve) | Used chunking with overlap (`chunk_size`, `chunk_overlap`) to preserve context; could experiment with sentence-based splits for higher integrity.          |\n",
    "| **Metadata Quality**           | Is the metadata complete, consistent, and informative?                             |  Yes                        | Kept important fields like `complaint_id`, `product`, `company`, and linked them to each chunk.                                                            |\n",
    "| **Embedding Quality**          | Are embeddings meaningful and relevant to query matching?                          |  Yes                        | Used `sentence-transformers/all-MiniLM-L6-v2`, a lightweight and high-performance model suitable for semantic search; tested with FAISS similarity scores. |\n",
    "| **Storage & Format**           | Is the data stored in a way that is fast and accessible?                           |  Yes                        | Used `FAISS` for retrieval speed, and saved metadata as a `pickle` file â€” fast and aligned with RAG design patterns.                                       |\n",
    "| **Performance Readiness**      | Can the data pipeline handle user queries efficiently?                             |  Yes                        | Vector store is indexed, embeddings precomputed, and retrieval is optimized (`top_k=5`).                                                                   |\n",
    "| **Encoding/Language Handling** | Are encodings (e.g., UTF-8), special characters, and multilingual support handled? |  Partial                    | I handled English text properly with normalization; for multilingual (e.g., Amharic), model and tokenizer choice needs adaptation.                       |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CA-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
